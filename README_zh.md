<div align="center">

![logo](./assets/bumblecore.jpg)

**å°æ ¸å¿ƒï¼Œå¤§è½°é¸£ | Small Core, Big Buzz**

ä¸€ä¸ªä»é›¶æ‰‹åŠ¨å®ç°çš„å¤§è¯­è¨€æ¨¡å‹è®­ç»ƒæ¡†æ¶ï¼Œè®©ä½ å®Œå…¨æŒæ§è®­ç»ƒçš„æ¯ä¸€ä¸ªç»†èŠ‚ï¼›  
æ¨¡å‹æ¶æ„åˆ°æ¨¡å‹æ¨ç†ï¼Œä»åˆ†å¸ƒå¼è®­ç»ƒåˆ°æŸå¤±è®¡ç®—ï¼Œä¸€åˆ‡éƒ½è§¦æ‰‹å¯åŠã€‚  

[![Python](https://img.shields.io/badge/Python-3.10%2B-blue)](https://www.python.org/)
[![DeepSpeed](https://img.shields.io/badge/DeepSpeed-Enabled-green)](https://github.com/microsoft/DeepSpeed)
[![License](https://img.shields.io/badge/License-Apache%202.0-yellow.svg)](https://opensource.org/licenses/Apache-2.0)

</div>

---

## é¡¹ç›®ç®€ä»‹

### æ ¸å¿ƒç‰¹æ€§

#### 1ï¸âƒ£ **å®Œå…¨æ‰‹åŠ¨å®ç°çš„è®­ç»ƒå¾ªç¯**

BumbleCore ä¸ä¾èµ–ä»»ä½•é«˜å±‚ Trainer åº“ï¼Œæ‰€æœ‰æ ¸å¿ƒç»„ä»¶å‡ä»åº•å±‚æ‰‹åŠ¨å®ç°ï¼š

- è‡ªå®šä¹‰æ•°æ®åŠ è½½å™¨å’Œé¢„å¤„ç†ç®¡é“
- æ‰‹åŠ¨é…ç½®åˆ†å¸ƒå¼è®­ç»ƒç¯å¢ƒï¼Œæ·±åº¦é›†æˆ DeepSpeed
- å®Œå…¨å¯æ§çš„å‰å‘ä¼ æ’­ã€åå‘ä¼ æ’­å’Œå‚æ•°æ›´æ–°æµç¨‹
- çµæ´»çš„æŸå¤±å‡½æ•°å®ç°ï¼Œæ”¯æŒå¤šä»»åŠ¡å­¦ä¹ 
- æ‰‹åŠ¨å®ç°çš„æ¨ç†ç”Ÿæˆæœºåˆ¶ï¼ŒåŒ…æ‹¬ Top-pã€Top-k é‡‡æ ·å’Œ KV Cache

> ğŸ’¡ **ä¸ºä»€ä¹ˆé€‰æ‹©æ‰‹åŠ¨å®ç°ï¼Ÿ**  
> æ‰‹åŠ¨å®ç°è®©ä½ æ·±å…¥ç†è§£æ¯ä¸€è¡Œä»£ç çš„ä½œç”¨ï¼Œä¾¿äºè°ƒè¯•ã€ä¼˜åŒ–å’Œåˆ›æ–°ã€‚æ— è®ºæ˜¯ç ”ç©¶æ–°çš„è®­ç»ƒç­–ç•¥ï¼Œè¿˜æ˜¯é’ˆå¯¹ç‰¹å®šåœºæ™¯è¿›è¡Œå®šåˆ¶åŒ–ä¼˜åŒ–ï¼ŒBumbleCore éƒ½èƒ½æä¾›æœ€å¤§çš„çµæ´»æ€§ã€‚

#### 2ï¸âƒ£ **Bumblebee æ¨¡å‹æ¶æ„ï¼šè‡ªç”±å®šåˆ¶ä½ çš„æ¨¡å‹**

å†…ç½®çš„ Bumblebee æ¶æ„ï¼ˆå‚è€ƒ Qwen2.5 è®¾è®¡ï¼‰æä¾›é«˜åº¦çµæ´»çš„é…ç½®èƒ½åŠ›ï¼š

- æ”¯æŒä»å°å‹å®éªŒæ¨¡å‹åˆ°å¤§è§„æ¨¡ç”Ÿäº§æ¨¡å‹çš„å‚æ•°é‡é…ç½®
- å¯åŠ¨æ€è°ƒæ•´ Transformer å±‚æ•°ã€æ³¨æ„åŠ›å¤´æ•°ã€éšè—å±‚ç»´åº¦ç­‰æ¶æ„å‚æ•°
- æ”¯æŒè‡ªå®šä¹‰æ¿€æ´»å‡½æ•°ã€å½’ä¸€åŒ–æ–¹å¼ã€æ³¨æ„åŠ›æœºåˆ¶ç­‰ç»„ä»¶
- æ¶µç›–å®Œæ•´è®­ç»ƒæµç¨‹ï¼šé¢„è®­ç»ƒï¼ˆPretrainingï¼‰ã€ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰ã€ç›´æ¥åå¥½ä¼˜åŒ–ï¼ˆDPOï¼‰

> **ä½¿ç”¨åœºæ™¯**  
> æƒ³è¦å¿«é€ŸéªŒè¯ä¸€ä¸ªæ–°çš„æ¨¡å‹è®¾è®¡ï¼Ÿæˆ–è€…é’ˆå¯¹ç‰¹å®šé¢†åŸŸè®­ç»ƒä¸€ä¸ªè½»é‡çº§æ¨¡å‹ï¼ŸBumblebee æ¶æ„è®©ä½ èƒ½å¤Ÿåœ¨å‡ åˆ†é’Ÿå†…å®Œæˆæ¨¡å‹é…ç½®ï¼Œå¼€å§‹è®­ç»ƒã€‚

#### 3ï¸âƒ£ **é€šç”¨è®­ç»ƒæ¡†æ¶ï¼šæ”¯æŒä¸»æµå¼€æºæ¨¡å‹**

- å…¼å®¹ Qwenã€LLaMAã€ChatGLM ç­‰å¼€æºæ¨¡å‹
- æ·±åº¦é›†æˆ DeepSpeedï¼Œæ”¯æŒ ZeRO ä¼˜åŒ–ã€æ··åˆç²¾åº¦è®­ç»ƒ
- æ”¯æŒé¢„è®­ç»ƒã€å¢é‡é¢„è®­ç»ƒã€æŒ‡ä»¤å¾®è°ƒã€å¼ºåŒ–å­¦ä¹ ï¼ˆRLHF/DPOï¼‰ç­‰å…¨æµç¨‹è®­ç»ƒ
- å†…ç½®æ¢¯åº¦ç´¯ç§¯ã€æ¢¯åº¦æ£€æŸ¥ç‚¹ã€æ¿€æ´»é‡è®¡ç®—ç­‰å†…å­˜ä¼˜åŒ–æŠ€æœ¯
- æ¨¡å—åŒ–è®¾è®¡ï¼Œä¾¿äºæ‰©å±•æ–°çš„æ¨¡å‹æ¶æ„å’Œè®­ç»ƒç­–ç•¥

---

## è®¾è®¡ç†å¿µ

BumbleCore çš„è®¾è®¡éµå¾ªä¸‰ä¸ªæ ¸å¿ƒåŸåˆ™ï¼š

1. **é€æ˜æ€§** - æ¯ä¸€è¡Œä»£ç éƒ½æ¸…æ™°å¯è§ï¼Œæ²¡æœ‰é»‘ç›’æ“ä½œ
2. **çµæ´»æ€§** - ä»æ•°æ®åˆ°æ¨¡å‹ï¼Œä»è®­ç»ƒåˆ°æ¨ç†ï¼Œä¸€åˆ‡éƒ½å¯å®šåˆ¶
3. **é«˜æ•ˆæ€§** - å……åˆ†åˆ©ç”¨ DeepSpeed ç­‰å·¥å…·ï¼Œç¡®ä¿è®­ç»ƒæ•ˆç‡

---

## è°é€‚åˆä½¿ç”¨ BumbleCoreï¼Ÿ

- æ·±åº¦å­¦ä¹ ç ”ç©¶è€…ï¼šéœ€è¦æ·±åº¦å®šåˆ¶è®­ç»ƒæµç¨‹ï¼ŒéªŒè¯æ–°ç®—æ³•å’Œæ¶æ„
- ç®—æ³•å·¥ç¨‹å¸ˆï¼šå¸Œæœ›å®Œå…¨æŒæ§æ¨¡å‹è®­ç»ƒç»†èŠ‚ï¼Œè¿›è¡Œæ€§èƒ½ä¼˜åŒ–
- å­¦ä¹ è€…ï¼šæƒ³è¦æ·±å…¥ç†è§£å¤§è¯­è¨€æ¨¡å‹è®­ç»ƒçš„åº•å±‚åŸç†
- ä¼ä¸šå›¢é˜Ÿï¼šéœ€è¦é’ˆå¯¹ç‰¹å®šä¸šåŠ¡åœºæ™¯å®šåˆ¶è®­ç»ƒæ–¹æ¡ˆ

---

## å®‰è£…

### ç¯å¢ƒè¦æ±‚

- Python >= 3.10
- Linux æ“ä½œç³»ç»Ÿ

### å®‰è£…æ­¥éª¤

**1. å…‹éš†ä»“åº“**

```bash
git clone https://github.com/wxhcore/bumblecore.git
cd bumblecore
```

**2. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ**

```bash
conda create -n bumblecore_env python=3.10 -y
conda activate bumblecore_env
```

**3. å®‰è£…ä¾èµ–**

åŸºç¡€å®‰è£…ï¼š

```bash
pip install -e .
```

å¯é€‰å®‰è£… FlashAttention-2ï¼š

```bash
pip install -e ".[flash-attn]" --no-build-isolation
```

---

## æ•°æ®å‡†å¤‡

BumbleCore æ”¯æŒä¸‰ç§è®­ç»ƒé˜¶æ®µçš„ä¸åŒæ•°æ®æ ¼å¼ï¼Œæ‰€æœ‰æ ¼å¼å‡æ”¯æŒ JSON å’Œ JSONLï¼Œæ¡†æ¶ä¼šè‡ªåŠ¨è¯†åˆ«ã€‚

### æ”¯æŒçš„æ ¼å¼
> ğŸ’¡ æ‰€æœ‰è®­ç»ƒé˜¶æ®µå‡æ”¯æŒ JSON å’Œ JSONL ä¸¤ç§æ ¼å¼ï¼Œæ¡†æ¶ä¼šè‡ªåŠ¨è¯†åˆ«ã€‚

| è®­ç»ƒé˜¶æ®µ | æ•°æ®æ ¼å¼ | 
|---------|---------|
| **é¢„è®­ç»ƒ** | `{"text": "..."}` |
| **SFT** | Alpaca / ShareGPT | 
| **DPO** | Alpaca / ShareGPTï¼ˆwith chosen/rejectedï¼‰ |

### æ•°æ®ç¤ºä¾‹

SFT Alpaca æ ¼å¼ï¼š

```json
{
  "instruction": "è§£é‡Šä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ",
  "input": "",
  "output": "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªåˆ†æ”¯..."
}
```

**[æŸ¥çœ‹å®Œæ•´æ•°æ®æ ¼å¼æ–‡æ¡£ â†’](./docs/DATA_FORMAT_zh.md)**

---

## é…ç½®è¯´æ˜

### Bumblebee æ¨¡å‹é…ç½®

BumbleCore æä¾›äº†ä» 0.5B åˆ° 72B çš„å¤šç§æ¨¡å‹è§„æ¨¡é…ç½®ï¼š

| å­—æ®µ | 0.5B | 1.5B | 3B | 7B | 14B | 32B | 72B |
|------|------|------|----|----|-----|-----|-----|
| **hidden_size** | 896 | 1536 | 2048 | 3584 | 5120 | 5120 | 8192 |
| **intermediate_size** | 4864 | 8960 | 11008 | 18944 | 13824 | 27648 | 29568 |
| **num_attention_heads** | 14 | 12 | 16 | 28 | 40 | 40 | 64 |
| **num_hidden_layers** | 24 | 28 | 36 | 28 | 48 | 64 | 80 |
| **num_key_value_heads** | 2 | 2 | 2 | 4 | 8 | 8 | 8 |
| **tie_word_embeddings** | true | true | true | false | false | false | false |
| **vocab_size** | 151936 | 151936 | 151936 | 152064 | 152064 | 152064 | 152064 |

é…ç½®æ–‡ä»¶ä½ç½®ï¼š`./models/bumblebee/config.json/`

### è®­ç»ƒå‚æ•°é…ç½®

**[æŸ¥çœ‹å®Œæ•´é…ç½®å‚æ•°æ–‡æ¡£ â†’](./docs/CONFIG_zh.md)**

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

BumbleCore æ”¯æŒçµæ´»çš„é…ç½®æ–¹å¼ï¼Œä»¥ä¸‹ä»¥ SFTï¼ˆç›‘ç£å¾®è°ƒï¼‰ä¸ºä¾‹å±•ç¤ºä¸åŒä½¿ç”¨æ–¹å¼ã€‚

é…ç½®ä¼˜å…ˆçº§ï¼šå‘½ä»¤è¡Œå‚æ•° > YAML é…ç½®æ–‡ä»¶ > TrainConfig é»˜è®¤å€¼

### æ–¹å¼ä¸€ï¼šä½¿ç”¨ YAML é…ç½®æ–‡ä»¶

```bash
deepspeed --include localhost:0,1 src/train.py \
    --yaml_config ./configs/sft/sft_full.yaml
```

### æ–¹å¼äºŒï¼šçº¯å‘½ä»¤è¡Œæ‰§è¡Œ

```bash
deepspeed --include localhost:0,1 src/train.py \
    --training_stage sft \
    --finetuning_type full \
    --model_name_or_path <your model path> \
    --dataset_path <your dataset path> \
    --output_dir <your save path> \
    --num_epochs 3.0 \
    --learning_rate 5e-5 \
    --train_micro_batch_size_per_gpu 4 \
    --gradient_accumulation_steps 4 \
    --train_model_precision bf16 \
    --deepspeed_config_path ./configs/deepspeed/ds_z2_config.json
```

### æ–¹å¼ä¸‰ï¼šå‘½ä»¤è¡Œè¦†ç›– YAML é…ç½®

```bash
deepspeed --include localhost:0,1 src/train.py \
    --yaml_config ./configs/sft/sft_lora.yaml \
    --learning_rate 1e-4
```

### ä½¿ç”¨ Shell è„šæœ¬

ä»¥ä¸Šä¸‰ç§æ–¹å¼éƒ½å¯ä»¥å†™æˆ Shell è„šæœ¬æ¥æ‰§è¡Œï¼Œä¾¿äºç®¡ç†å’Œå¤ç”¨ã€‚

BumbleCore åœ¨ `scripts/` ç›®å½•ä¸‹å·²æä¾›é¢„é…ç½®çš„è®­ç»ƒè„šæœ¬ã€‚

**ä½¿ç”¨æ­¥éª¤**ï¼š

1. ç¼–è¾‘è„šæœ¬ï¼Œä¿®æ”¹æ¨¡å‹è·¯å¾„ã€æ•°æ®é›†è·¯å¾„ç­‰å‚æ•°
2. æ‰§è¡Œè„šæœ¬å¼€å§‹è®­ç»ƒ

```bash
bash scripts/sft_full.sh
```

---

## ä¸‰é˜¶æ®µå®Œæ•´è®­ç»ƒå®éªŒ

æä¾›äº†ä»é›¶å¼€å§‹è®­ç»ƒå®Œæ•´è¯­è¨€æ¨¡å‹çš„å®éªŒæ•™ç¨‹ï¼Œæ¶µç›–é¢„è®­ç»ƒã€ç›‘ç£å¾®è°ƒã€åå¥½ä¼˜åŒ–ä¸‰ä¸ªé˜¶æ®µã€‚

### å®éªŒé…ç½®

| é˜¶æ®µ | æ•°æ®é›† | è§„æ¨¡ | è¾“å‡º |
|------|--------|------|------|
| **é¢„è®­ç»ƒ** | [mini_pretrain_dataset](https://www.modelscope.cn/datasets/BazingaLyn/mini_pretrain_dataset) | 1B tokens | åŸºåº§æ¨¡å‹ |
| **ç›‘ç£å¾®è°ƒ** | [alpaca_gpt4_zh](https://huggingface.co/datasets/llamafactory/alpaca_gpt4_zh) | 42.7K samples | æŒ‡ä»¤æ¨¡å‹ |
| **åå¥½ä¼˜åŒ–** | [DPO-En-Zh-20k](https://huggingface.co/datasets/llamafactory/DPO-En-Zh-20k) | 10K samples (zh) | å¯¹é½æ¨¡å‹ |

**[æŸ¥çœ‹å®Œæ•´å®éªŒæ•™ç¨‹ â†’](./docs/TUTORIAL_zh.md)**

---

## LoRA æƒé‡åˆå¹¶

ä½¿ç”¨ LoRA è®­ç»ƒåï¼Œå¯ä»¥å°† LoRA æƒé‡åˆå¹¶å›åŸºåº§æ¨¡å‹ï¼Œç”Ÿæˆå®Œæ•´çš„æ¨¡å‹æ–‡ä»¶ã€‚

```bash
# ç¼–è¾‘ tools/run_merge_lora.sh ä¿®æ”¹æ¨¡å‹è·¯å¾„å‚æ•°åæ‰§è¡Œ
bash tools/run_merge_lora.sh
```

---

## æ¨¡å‹æ¨ç†

è®­ç»ƒå®Œæˆåï¼ŒBumbleCore æä¾›çµæ´»çš„æ¨ç†æ–¹å¼ï¼Œæ”¯æŒ YAML é…ç½®å’Œå‘½ä»¤è¡Œå‚æ•°ã€‚

### å‘½ä»¤è¡Œäº¤äº’å¼å¯¹è¯

é…ç½®æ–‡ä»¶ï¼š`configs/inference/chat.yaml`

```bash
bash scripts/chat.sh
```

### Web ç•Œé¢ï¼ˆBumbleChatï¼‰

é…ç½®æ–‡ä»¶ï¼š`configs/inference/bumblechat.yaml`

```bash
bash scripts/bumblechat.sh
```

![BumbleChat Web ç•Œé¢](assets/bumblechat.png)

æœåŠ¡å¯åŠ¨åæ”¯æŒ OpenAI å…¼å®¹çš„ API è°ƒç”¨ï¼š

```python
from openai import OpenAI

client = OpenAI(
    base_url="<å¯åŠ¨æœåŠ¡çš„apiåœ°å€>/v1",
    api_key="dummy" 
)

response = client.chat.completions.create(
    model="bumblebee", 
    messages=[
        {"role": "user", "content": "ä½ å¥½ï¼Œä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±"}
    ],
    temperature=0.7,
    max_completion_tokens=2048
)

print(response.choices[0].message.content)
```

---
