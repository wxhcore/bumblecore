training_stage: "pretrain" 
finetuning_type: "full"

# Model & Tokenizer
model_name_or_path: "<your base model path>"
trust_remote_code: true
tokenizer_use_fast: true

# Dataset
dataset_path: "<your dataset path>"
cutoff_len: 2048

# Training
num_epochs: 3.0
learning_rate: 5e-5
weight_decay: 0.01
lr_scheduler_type: "cosine"
enable_gradient_checkpointing: true
warmup_ratio: 0.1

# Batch Size
train_micro_batch_size_per_gpu: 4
gradient_accumulation_steps: 4

# Precision
train_model_precision: "bf16"

# DeepSpeed
deepspeed_config_path: "./configs/deepspeed/ds_z2_config.json"  

# Save & Log
output_dir: "<your output directory>"
save_steps: 3000
save_total_limit: 3
save_last: true
logging_steps: 1
save_train_log: true
use_tensorboard: true


average_tokens_across_devices: false
num_local_io_workers: null  # 整数，不传则根据gpu数量自动计算