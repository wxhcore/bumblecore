# BumbleCore 详细功能特性

本文档详细介绍 BumbleCore 训练框架的各项功能特性和技术细节。

---

## 🚀 训练能力

### 多阶段训练支持

BumbleCore 支持大语言模型训练的完整生命周期，从零开始到强化学习：

- **预训练（Pretrain）**：从配置文件初始化模型，从零开始训练
  - 支持从 config 创建全新模型
  - 适用于完全自定义的模型架构
  
- **增量预训练（Continue Pretrain）**：在已有模型基础上继续预训练
  - 加载预训练权重继续训练
  - 适用于领域适配和知识注入
  
- **监督微调（SFT）**：基于指令-回复对进行有监督微调
  - 支持对话格式数据
  - 自动处理指令和回复的标注
  - 提升模型的指令遵循能力
  
- **直接偏好优化（DPO）**：使用偏好数据进行强化学习
  - 无需独立的奖励模型
  - 基于人类偏好对进行优化

### DeepSpeed 深度集成

BumbleCore 与 DeepSpeed 深度集成，充分发挥分布式训练的潜力：

#### ZeRO 优化
完整支持 ZeRO（Zero Redundancy Optimizer）的所有阶段：

- **ZeRO Stage 0**：基础 DDP（Distributed Data Parallel）
- **ZeRO Stage 1**：优化器状态分片
- **ZeRO Stage 2**：优化器状态 + 梯度分片
- **ZeRO Stage 3**：优化器状态 + 梯度 + 模型参数分片
  - 特别优化：自动处理模型初始化和检查点保存
  - 智能通信调优：根据模型 `hidden_size` 自动优化通信 bucket 大小
  - 内存效率：可训练数百亿参数模型

#### 混合精度训练
灵活的精度选择，平衡速度和精度：

- **FP16（Float16）**：半精度训练
  - 显存占用减半
  - 计算速度显著提升
  - 自动梯度缩放
  
- **BF16（Brain Float 16）**：脑浮点训练
  - 更大的数值范围
  - 更好的训练稳定性
  - 适用于大规模模型
  
- **自动处理**：精度转换和梯度缩放完全自动化

### 高效内存管理

多种内存优化技术，让有限的 GPU 显存训练更大的模型：

#### 梯度检查点（Gradient Checkpointing）
- 牺牲少量计算时间换取显著的显存节省
- 适用于超大模型训练
- 可配置开关，灵活控制

#### 梯度累积（Gradient Accumulation）
- 模拟更大的批量大小
- 多个 micro-batch 累积后再更新参数
- 在显存受限时仍能享受大 batch size 的训练稳定性

#### FlashAttention-2
- 自动检测环境中是否可用
- 显著加速注意力计算（2-4x）
- 降低显存占用
- 无需代码修改，自动启用

#### 智能数据加载
- **自适应 DataLoader Workers**：默认 `2 × GPU 数量`
- **自定义 Workers 数量**：可通过配置精确控制
- **Persistent Workers**：减少 worker 重启开销
- **Pin Memory**：加速 CPU-GPU 数据传输
- **DistributedSampler**：确保数据在多 GPU 间均匀分布

---

## 🎯 参数高效微调

### LoRA 支持

完整支持 LoRA（Low-Rank Adaptation）技术，大幅降低微调成本：

#### 核心特性
- **基于 PEFT 库**：无缝集成到训练流程
- **全流程支持**：从训练到保存到推理
- **参数效率**：仅训练 0.1%-1% 的参数
- **性能保持**：接近全参数微调的效果

#### 灵活配置
- **Rank (r)**：控制低秩矩阵的维度
  - 通常取值：8, 16, 32, 64
  - 越大表示能力越强，但参数量也越大
  
- **Alpha**：缩放因子
  - 控制 LoRA 层的影响力
  - 通常设置为 `2 × rank`
  
- **Target Modules**：指定要应用 LoRA 的层
  - 可选择性地应用于 Query、Key、Value、Output 等
  - 灵活控制训练范围和参数量
  
- **Dropout**：LoRA 层的 dropout 率
  - 防止过拟合
  - 提升泛化能力

#### 检查点优化
- **仅保存 LoRA 参数**：checkpoint 大小从几十 GB 降到几十 MB
- **快速保存和加载**：大幅减少 I/O 时间
- **存储友好**：可保存大量实验版本

#### 可训练参数统计
- 自动打印训练参数占比
- 清晰展示 LoRA 的参数效率
- 便于调优和对比实验

---

## 📊 训练监控与日志

### 多维度指标记录

实时记录和展示训练过程中的关键指标：

#### 实时训练指标
- **Loss（损失值）**：
  - 每个训练步记录
  - 支持梯度累积后的平均 loss
  - 跨设备聚合，确保准确性
  
- **Learning Rate（学习率）**：
  - 实时追踪学习率变化
  - 验证调度器是否正常工作
  
- **Gradient Norm（梯度范数）**：
  - 监控梯度大小
  - 及时发现梯度爆炸或消失
  - 辅助调优
  
- **Epoch 进度**：
  - 精确的训练进度
  - 支持小数 epoch（如 2.37 epoch）

#### TensorBoard 集成
专业的可视化工具，实时查看训练曲线：

- **实时可视化训练曲线**：
  - Loss 曲线
  - Learning Rate 曲线
  - Gradient Norm 曲线
  
- **自动记录所有关键指标**：
  - 每个 logging step 自动写入
  - 无需额外代码
  
- **支持多实验对比**：
  - 在同一个 TensorBoard 中对比多个实验
  - 便于超参数调优

#### 训练指标持久化
除了 TensorBoard，还提供原始数据保存：

- **JSON 格式保存完整训练历史**：
  - 包含所有 step 的详细指标
  - 易于后处理和分析
  - 可用于自定义可视化
  
- **自动生成训练损失曲线图**：
  - PNG 格式，直接查看
  - 训练结束时自动生成
  
- **支持平滑曲线绘制**：
  - SFT/DPO 阶段启用平滑
  - 预训练阶段显示原始数据
  - 更清晰地观察趋势

### 进度追踪

#### TQDM 进度条
- 实时显示训练进度百分比
- 显示训练速度（steps/s）
- 估算剩余时间
- 仅在主进程显示，避免输出混乱

#### 详细日志输出
- **可选的文件日志保存**：
  - 保存到 `output_dir/logs/train.log`
  - 完整记录所有日志信息
  - 便于事后分析
  
- **格式化的训练参数打印**：
  - 训练开始时打印完整配置
  - 数据量、batch size、总步数等
  - 便于复现实验
  
- **特性启用情况总结**：
  - 列出所有启用的功能
  - LoRA、FlashAttention、Gradient Checkpointing 等
  - 一目了然的配置概览

---

## 💾 检查点管理

### 智能保存策略

#### 定期保存
- 按 `save_steps` 自动保存检查点
- 可配置保存频率
- 支持断点续训

#### 检查点轮换
- 基于 `save_total_limit` 自动删除旧检查点
- 队列式管理，始终保留最新的 N 个检查点
- 节省存储空间
- 保留训练过程中的关键节点

#### 最终检查点
- 训练结束时可选保存最后一个模型
- `save_last=True` 时启用
- 独立于轮换机制，永久保留

#### ZeRO Stage 3 兼容
ZeRO Stage 3 下参数分片到多个 GPU，保存和加载需要特殊处理：

- **自动转换 ZeRO 分片参数为完整模型**：
  - 使用 DeepSpeed 提供的转换工具
  - 将分片参数合并为完整模型
  
- **FP32 精度恢复后转换回训练精度**：
  - 先转换为 FP32 确保精度
  - 再转换回 FP16/BF16 节省空间
  
- **使用 SafeTensors 格式保存**：
  - 更安全的序列化格式
  - 防止恶意代码注入
  - 更快的加载速度

### 完整模型保存

每个检查点包含模型训练和推理所需的所有文件：

#### 模型权重
- **SafeTensors 格式**：安全、高效
- **Sharded 保存**：支持超大模型（默认 5GB 每个分片）
- **兼容 Hugging Face**：可直接用于 `from_pretrained`

#### 分词器
- 自动保存完整的 Tokenizer 配置
- 包括词表、特殊 token、chat template 等
- 确保推理时 tokenization 一致

#### 训练状态
- **优化器状态**：支持断点续训
- **调度器状态**：学习率调度器恢复
- **随机种子**：确保训练可复现

---

## 🔧 优化器与调度器

### 优化器

#### AdamW
- 默认使用 AdamW（Adam with Weight Decay）
- 业界大模型训练的标准选择
- 稳定且收敛效果好

#### 权重衰减
- 可配置的 `weight_decay`
- L2 正则化，防止过拟合
- 通常取值：0.01, 0.1

#### 参数分组
- 支持对不同参数应用不同的优化策略
- 可扩展：例如对 bias 和 LayerNorm 不应用 weight decay
- 代码中已包含实现示例（注释部分）

### 学习率调度

#### 多种调度器
支持 Hugging Face Transformers 的所有调度器类型：

- **linear**：线性衰减
  - 简单有效
  - 适用于大多数场景
  
- **cosine**：余弦衰减
  - 平滑的学习率变化
  - 通常比 linear 效果更好
  
- **cosine_with_restarts**：带重启的余弦衰减
  - 周期性重启学习率
  - 有助于跳出局部最优
  
- **polynomial**：多项式衰减
  - 可控的衰减曲线
  
- **constant**：恒定学习率
  - 适用于特定场景
  
- **constant_with_warmup**：Warmup 后恒定
  - 结合 warmup 和恒定学习率

- **inverse_sqrt**：平方根倒数衰减
  - 学习率按步数的平方根倒数衰减
  - 常用于 Transformer 模型

- **reduce_on_plateau**：基于指标动态调整
  - 当指标不再改善时降低学习率
  - 需要监控验证指标

- **cosine_with_min_lr**：带最小学习率的余弦衰减
  - 余弦衰减但不会降到零
  - 保持一定的最小学习率

- **warmup_stable_decay**：预热-稳定-衰减三阶段
  - 先预热，后稳定，最后衰减
  - 适合长时间训练

#### Warmup 支持
- 可配置的 `warmup_ratio`
- 训练初期逐渐增加学习率
- 提升训练稳定性
- 通常取值：0.03, 0.05, 0.1

#### 自动步数计算
- 根据 epoch、batch size 和数据量自动计算总步数
- 自动计算 warmup steps
- 无需手动计算，减少配置错误

---

## 🌐 分布式训练

### 完整的分布式支持

#### 自动环境初始化
- 一键初始化 DeepSpeed 分布式环境
- 自动检测分布式配置
- 兼容各种启动方式（torchrun、deepspeed launcher）

#### 设备管理
- 自动设置 CUDA 设备和 local rank
- 每个进程绑定到对应的 GPU
- 避免多进程冲突

#### 跨设备通信
- **损失聚合（All-Reduce）**：
  - 将各 GPU 的损失聚合求平均
  - 确保日志中的 loss 是全局平均值
  
- **可选的跨设备 token 平均**：
  - `average_tokens_across_devices=True` 时启用
  - 避免不同设备数据量差异影响梯度计算
  - 提升训练稳定性
  
- **梯度同步**：
  - DeepSpeed 自动处理梯度 All-Reduce
  - 支持梯度压缩等优化

#### Rank 管理
主进程专属操作自动处理，避免重复执行：

- **日志输出**：仅主进程打印日志
- **检查点保存**：仅主进程保存（ZeRO Stage 3 除外）
- **绘图和可视化**：仅主进程生成图表
- **TensorBoard 写入**：仅主进程写入
- **进度条显示**：仅主进程显示 TQDM

---

## 📈 损失计算

### 灵活的损失实现

#### 手动实现的 CausalLM Loss
- 不依赖 Hugging Face 的默认实现
- 完全可控的损失计算逻辑
- 便于定制和扩展

#### 跨设备平均
- 可选的跨设备 token 计数平均
- 确保训练稳定性
- 特别适用于数据长度差异大的场景

---
